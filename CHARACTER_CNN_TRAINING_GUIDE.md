# Character-CNN Model Training Guide for PhishGuard

## Overview

This guide explains how to train and use the Character-CNN (Convolutional Neural Network) model for phishing URL detection in PhishGuard using TensorFlow.js and your CSV datasets.

## Character-CNN Architecture

The Character-CNN model processes URLs at the character level, extracting features that distinguish phishing URLs from legitimate ones.

### Model Structure

```
Input Layer (URL as character indices)
    â†“
Embedding Layer (64 dimensions)
    â†“
Convolution Layers (3 parallel branches: 3Ã—64, 4Ã—64, 5Ã—64 filters)
    â†“
Max Pooling (per filter)
    â†“
Concatenation of pooled outputs
    â†“
Dense Layer (128 units, ReLU)
    â†“
Dropout (0.5)
    â†“
Output Layer (1 unit, Sigmoid - Binary Classification)
```

### Why Character-CNN for URLs?

1. **Character-Level Processing**: Analyzes URL structure at the character level, catching subtle phishing patterns
2. **Local Feature Extraction**: Convolutional filters capture n-gram patterns (3-5 character sequences)
3. **Lightweight**: Suitable for in-browser training and inference with TensorFlow.js
4. **Domain Knowledge**: Different filter sizes capture various URL components (domain, path, parameters)

## CSV Dataset Format

Your datasets should follow this structure:

```csv
url,is_phishing
http://example.com,0
http://phishing-example.com,1
https://legitimate-bank.com,0
```

### Supported Column Names

- **URL columns**: `url`, `link`, `domain`, `website`
- **Label columns**: `is_phishing`, `isphishing`, `phishing`, `label`, `class`, `type`, `category`

### Label Format

- Phishing: `1`, `true`, or `phishing`
- Legitimate: `0`, `false`, or `legitimate`

## Implementation Files

### 1. Core Model (`src/lib/ml/character-cnn-model.ts`)

```typescript
import { CharacterCNNModel } from '@/lib/ml/character-cnn-model';

// Initialize model
const model = new CharacterCNNModel({
  maxSequenceLength: 200,
  embeddingDim: 64,
  vocabularySize: 128,
});

// Build TensorFlow.js model
await model.build();
```

**Key Methods:**

- `build()`: Construct the TensorFlow.js model architecture
- `urlToIndices(url)`: Convert URL string to character indices
- `predict(url)`: Make predictions on a single URL
- `predictBatch(urls)`: Make predictions on multiple URLs
- `getModel()`: Get the underlying TensorFlow.js model

### 2. Training Service (`src/lib/ml/character-cnn-training-service.ts`)

```typescript
import { CharacterCNNTrainingService } from '@/lib/ml/character-cnn-training-service';

const trainingService = new CharacterCNNTrainingService(model);

// Train model
const result = await trainingService.train(
  [
    { url: 'http://example.com', label: 0 },
    { url: 'http://phishing.com', label: 1 },
    // ... more data
  ],
  {
    epochs: 20,
    batchSize: 32,
    learningRate: 0.001,
    validationSplit: 0.2,
    earlyStoppingPatience: 5,
  }
);

console.log(result.metrics); // Loss, Accuracy, Precision, Recall, F1
```

**Features:**

- Automatic data splitting (training/validation)
- Early stopping to prevent overfitting
- Real-time training progress tracking
- Comprehensive metrics calculation (accuracy, precision, recall, F1)

### 3. URL Data Processor (`src/lib/ml/url-data-processor.ts`)

Handles loading and preprocessing CSV data:

```typescript
import { URLDataProcessor } from '@/lib/ml/url-data-processor';

const processor = new URLDataProcessor();

// Load from CSV file
const data = await processor.loadFromCSV(csvFile);

// Load from URL
const data = await processor.loadFromURL('https://example.com/data.csv');

// Get dataset statistics
const stats = processor.getStatistics(data);
console.log(stats);
// { totalRecords: 1000, phishingCount: 450, legitimateCount: 550, ... }
```

### 4. Model Persistence (`src/lib/ml/model-persistence.ts`)

Save and load trained models:

```typescript
import { ModelPersistence } from '@/lib/ml/model-persistence';

const persistence = new ModelPersistence();

// Save model
await persistence.saveModel(model, 'phishing-detector-v1');

// Load model
const loadedModel = await persistence.loadModel('phishing-detector-v1');
```

### 5. CSV Data Loading Edge Function (`functions/load-csv-data/index.ts`)

Serverless function for loading and preprocessing CSV data:

**Endpoint**: `POST https://eky2mdxr-*.deno.dev`

**Request:**
```json
{
  "csvUrl": "https://example.com/phishing-urls.csv"
}
```

or

```json
{
  "csvContent": "url,is_phishing\nhttp://example.com,0\n..."
}
```

**Response:**
```json
{
  "success": true,
  "data": [
    { "url": "http://example.com", "isPhishing": false, "label": 0 },
    { "url": "http://phishing.com", "isPhishing": true, "label": 1 }
  ],
  "stats": {
    "totalRecords": 100,
    "phishingCount": 45,
    "legitimateCount": 55,
    "validUrls": 100,
    "invalidUrls": 0
  }
}
```

## Quick Start: Train Character-CNN

### Step 1: Prepare Your Data

Place your CSV files in the project:
- `dataset.csv`
- `dataset_phishing.csv`
- `Phishing_Legitimate_full.csv`

### Step 2: Load CSV Data

```typescript
import { URLDataProcessor } from '@/lib/ml/url-data-processor';

const processor = new URLDataProcessor();

// Option A: Load from local file
const fileInput = document.getElementById('csvInput') as HTMLInputElement;
const file = fileInput.files[0];
const data = await processor.loadFromCSV(file);

// Option B: Load from URL using edge function
const response = await fetch('https://eky2mdxr-ba194aemtb77.deno.dev', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    csvUrl: 'https://firebasestorage.googleapis.com/v0/b/.../dataset.csv'
  })
});
const { data } = await response.json();
```

### Step 3: Initialize and Build Model

```typescript
import { CharacterCNNModel } from '@/lib/ml/character-cnn-model';

const model = new CharacterCNNModel();
await model.build();
```

### Step 4: Train the Model

```typescript
import { CharacterCNNTrainingService } from '@/lib/ml/character-cnn-training-service';

const trainingService = new CharacterCNNTrainingService(model);

const result = await trainingService.train(data, {
  epochs: 20,
  batchSize: 32,
  learningRate: 0.001,
  validationSplit: 0.2,
  earlyStoppingPatience: 5,
});

console.log('âœ… Training Complete!');
console.log(`Accuracy: ${(result.metrics.accuracy * 100).toFixed(2)}%`);
console.log(`F1 Score: ${result.metrics.f1Score.toFixed(4)}`);
```

### Step 5: Use Model for Predictions

```typescript
// Single URL
const prediction = await model.predict('http://suspicious-bank.com');
console.log(`Threat: ${prediction.isPhishing ? 'ðŸš¨ PHISHING' : 'âœ… LEGITIMATE'}`);
console.log(`Confidence: ${(prediction.confidence * 100).toFixed(2)}%`);

// Batch predictions
const predictions = await model.predictBatch([
  'http://example.com',
  'http://phishing-attempt.com',
  'http://bank-fraud.com'
]);
```

## Integration with PhishGuard Scanner

The Character-CNN model is automatically integrated into the phishing analysis pipeline:

```typescript
import { PredictionService } from '@/lib/ml/prediction-service';

const service = new PredictionService();
await service.initialize();

// For URL scanning
const urlAnalysis = await service.analyzeCharacterCNNURL('http://suspicious.com');
console.log(urlAnalysis);
// {
//   algorithm: 'Character-CNN',
//   isPhishing: true,
//   confidence: 0.94,
//   indicators: ['suspicious-tld', 'typosquatting-pattern'],
//   analysisDetails: { ... }
// }
```

## Training Configuration

### Recommended Settings

**For Balanced Dataset:**
```json
{
  "epochs": 20,
  "batchSize": 32,
  "learningRate": 0.001,
  "validationSplit": 0.2,
  "earlyStoppingPatience": 5
}
```

**For Large Dataset (1000+):**
```json
{
  "epochs": 30,
  "batchSize": 64,
  "learningRate": 0.0005,
  "validationSplit": 0.2,
  "earlyStoppingPatience": 7
}
```

**For Small Dataset (<300):**
```json
{
  "epochs": 50,
  "batchSize": 16,
  "learningRate": 0.001,
  "validationSplit": 0.25,
  "earlyStoppingPatience": 10
}
```

## Key Hyperparameters Explained

### Model Architecture
- **maxSequenceLength** (200): Maximum URL length (chars)
  - URLs longer than this are truncated
  - Shorter URLs are padded with zeros

- **embeddingDim** (64): Character embedding dimension
  - Higher = more expressive but slower training
  - 64 is optimal for URL phishing detection

- **vocabularySize** (128): Number of unique characters
  - Covers standard ASCII printable characters
  - Sufficient for URL character set

### Training Parameters
- **epochs** (20): Number of complete passes through the dataset
  - More epochs = better training but risk of overfitting
  - Use early stopping to find optimal point

- **batchSize** (32): Samples per gradient update
  - Larger = faster but less precise gradients
  - Smaller = slower but better convergence

- **learningRate** (0.001): Gradient descent step size
  - Higher = faster learning but may overshoot
  - Lower = slower but more stable convergence

- **validationSplit** (0.2): Percentage of data for validation
  - Used to monitor overfitting during training
  - Not used in final performance reporting

- **earlyStoppingPatience** (5): Epochs without improvement before stopping
  - Prevents wasting time on plateaued training
  - Saves resources while maintaining performance

## Expected Performance Metrics

Based on training with phishing URL datasets:

| Metric | Expected Range | Notes |
|--------|---|---|
| **Accuracy** | 92-96% | Overall correctness |
| **Precision** | 89-94% | False positive rate control |
| **Recall** | 91-96% | Phishing detection rate |
| **F1 Score** | 0.90-0.95 | Harmonic mean of precision & recall |

## Troubleshooting

### Issue: Low Accuracy

**Causes:**
- Dataset too small (<500 samples)
- Imbalanced classes (too many legitimate, too few phishing)
- Poor data quality

**Solutions:**
- Add more training data
- Use data augmentation techniques
- Balance class distribution
- Increase epochs with early stopping

### Issue: Training Too Slow

**Causes:**
- Large batch size
- Large embedding dimension
- Browser memory limitations

**Solutions:**
- Reduce batchSize (32 â†’ 16)
- Reduce embeddingDim (64 â†’ 32)
- Use edge function for training (Deno runtime)
- Split dataset into smaller batches

### Issue: Model Overfitting

**Causes:**
- Too many epochs
- High learning rate
- Model too complex

**Solutions:**
- Enable early stopping with lower patience (3-5)
- Reduce learningRate (0.001 â†’ 0.0005)
- Increase dropout rate (0.5 â†’ 0.7)
- Use more training data

### Issue: Memory Out of Memory (OOM)

**Causes:**
- Too many samples in memory
- Large embedding dimensions
- Large batch size

**Solutions:**
- Reduce batch size
- Process data in smaller chunks
- Use IndexedDB for larger datasets
- Deploy training to edge function

## Advanced Usage

### Custom Preprocessing

```typescript
import { URLDataProcessor } from '@/lib/ml/url-data-processor';

const processor = new URLDataProcessor();
const data = await processor.loadFromCSV(file);

// Filter data
const filtered = data.filter(d => d.url.length > 10);

// Augment data (duplicate and slightly modify)
const augmented = processor.augmentData(filtered, 1.5);
```

### Monitoring Training Progress

```typescript
const trainingService = new CharacterCNNTrainingService(model);

// Setup progress monitor
const progressInterval = setInterval(() => {
  const progress = trainingService.getProgress();
  if (progress) {
    console.log(`Epoch ${progress.epoch}/${progress.totalEpochs}`);
    console.log(`Progress: ${progress.progress}%`);
    console.log(`Loss: ${progress.loss.toFixed(4)}`);
    console.log(`Accuracy: ${progress.accuracy.toFixed(4)}`);
  }
}, 1000);

// Start training
const result = await trainingService.train(data, config);
clearInterval(progressInterval);
```

### Model Evaluation

```typescript
const testData = [
  { url: 'http://test-phishing.com', label: 1 },
  { url: 'http://test-legitimate.com', label: 0 },
  // ... more test samples
];

const metrics = await trainingService.evaluate(
  testData.map(d => d.url),
  testData.map(d => d.label)
);

console.log('Test Metrics:');
console.log(`Accuracy: ${(metrics.accuracy * 100).toFixed(2)}%`);
console.log(`Precision: ${(metrics.precision * 100).toFixed(2)}%`);
console.log(`Recall: ${(metrics.recall * 100).toFixed(2)}%`);
console.log(`F1 Score: ${metrics.f1Score.toFixed(4)}`);
```

## File Locations

```
src/lib/ml/
â”œâ”€â”€ character-cnn-model.ts              # Core model architecture
â”œâ”€â”€ character-cnn-training-service.ts   # Training pipeline
â”œâ”€â”€ url-data-processor.ts               # CSV data processing
â”œâ”€â”€ model-persistence.ts                # Save/load models
â””â”€â”€ index.ts                            # Exports

functions/
â””â”€â”€ load-csv-data/index.ts              # CSV loading edge function
```

## API Reference

### CharacterCNNModel

```typescript
class CharacterCNNModel {
  // Lifecycle
  build(): Promise<void>
  
  // Prediction
  predict(url: string): Promise<{
    isPhishing: boolean
    confidence: number
    threatLevel: string
  }>
  
  predictBatch(urls: string[]): Promise<Array<{
    url: string
    isPhishing: boolean
    confidence: number
  }>>
  
  // Utility
  urlToIndices(url: string): number[]
  getModel(): tf.LayersModel | null
  getMaxSequenceLength(): number
  getVocabularySize(): number
  dispose(): void
}
```

### CharacterCNNTrainingService

```typescript
class CharacterCNNTrainingService {
  // Training
  train(data: URLDataPoint[], config?: TrainingConfig): Promise<TrainingResult>
  
  // Evaluation
  evaluate(testUrls: string[], testLabels: number[]): Promise<{
    accuracy: number
    loss: number
    precision: number
    recall: number
    f1Score: number
  }>
  
  // Monitoring
  getProgress(): TrainingProgress | null
  isTrainingInProgress(): boolean
  
  // Data
  prepareTrainingData(
    data: URLDataPoint[],
    validationSplit?: number
  ): { trainUrls, trainLabels, valUrls, valLabels }
}
```

## Next Steps

1. **Deploy Edge Function**: `blink deploy functions/load-csv-data`
2. **Train Model**: Use the CharacterCNNTrainingInterface component
3. **Evaluate**: Test on your datasets
4. **Integrate**: Use predictions in Scanner component
5. **Monitor**: Track model performance over time

## Support

For issues or questions:
- Check troubleshooting section
- Review training logs
- Verify dataset format
- Check browser console for errors
