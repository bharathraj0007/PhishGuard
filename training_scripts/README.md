# üéì PhishGuard ML Training Scripts

**Real Machine Learning Models for Academic Defense**

This directory contains **production-ready Python training scripts** for all four phishing detection models used in PhishGuard.

---

## üìÅ Directory Contents

```
training_scripts/
‚îú‚îÄ‚îÄ url_cnn_training.py         # URL Character-CNN model
‚îú‚îÄ‚îÄ email_bert_training.py      # Email Bi-LSTM / DistilBERT model
‚îú‚îÄ‚îÄ sms_bilstm_training.py      # SMS Bi-LSTM model
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îî‚îÄ‚îÄ README.md                   # This file
```

---

## üöÄ Quick Start (5 Steps)

### 1. Install Dependencies

```bash
# Create virtual environment
python3 -m venv ml_env
source ml_env/bin/activate  # Windows: ml_env\Scripts\activate

# Install packages
pip install -r requirements.txt
```

### 2. Download Datasets

**Option A: Kaggle CLI (Recommended)**

```bash
# Install Kaggle CLI
pip install kaggle

# Setup Kaggle credentials
# 1. Go to https://www.kaggle.com/settings
# 2. Click "Create New API Token"
# 3. Move downloaded kaggle.json to ~/.kaggle/

# Download datasets
kaggle datasets download -d taruntiwarihp/phishing-site-urls
kaggle datasets download -d subhajournal/phishingemails  
kaggle datasets download -d uciml/sms-spam-collection-dataset

# Unzip
unzip phishing-site-urls.zip
unzip phishingemails.zip
unzip sms-spam-collection-dataset.zip
```

**Option B: Manual Download**

1. [URL Dataset](https://www.kaggle.com/datasets/taruntiwarihp/phishing-site-urls)
2. [Email Dataset](https://www.kaggle.com/datasets/subhajournal/phishingemails)
3. [SMS Dataset](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)

### 3. Train Models

```bash
# Train URL model (~15 min)
python url_cnn_training.py phishing_urls.csv

# Train Email model (~30 min for LSTM, ~2 hours for BERT)
python email_bert_training.py emails.csv

# Train SMS model (~20 min)
python sms_bilstm_training.py spam.csv
```

### 4. Verify Output

Check that models were created:

```bash
ls -lh public/models/url/
ls -lh public/models/email/
ls -lh public/models/sms/
```

Expected files:
- `model.json` - Model architecture
- `group1-shard*.bin` - Model weights
- `metadata.json` - Training metrics
- `vocabulary.json` - Word vocabulary (email/sms only)

### 5. Deploy to Web App

```bash
# Copy models to your PhishGuard project
cp -r public/models/* ../public/models/

# Or if in different location:
cp -r public/models/* /path/to/phishguard/public/models/
```

---

## üìä Model Details

### 1. URL Character-CNN (`url_cnn_training.py`)

**Purpose**: Detect phishing URLs using character-level patterns

**Architecture**:
- Character embedding (128 vocab, 64 dims)
- 3x Conv1D layers (128 ‚Üí 256 ‚Üí 512 filters)
- Dense layers with dropout
- Binary classification output

**Input**: URL string (max 200 chars)  
**Output**: Phishing probability (0-1)

**Expected Performance**:
- Accuracy: 90-95%
- Training time: 15-20 minutes (CPU)

**Dataset Requirements**:
- CSV with columns: `url`, `label`
- Labels: 0 (safe), 1 (phishing)
- Minimum 10,000 samples

---

### 2. Email Bi-LSTM / DistilBERT (`email_bert_training.py`)

**Purpose**: Detect phishing emails using NLP

**Two Model Options**:

#### Option A: Bi-LSTM (Default, TensorFlow.js Compatible)

**Architecture**:
- Word embedding (10k vocab, 128 dims)
- 2x Bidirectional LSTM layers
- Dense layers with dropout
- Binary classification output

**Use when**: Browser deployment needed  
**Accuracy**: 92-95%  
**Training time**: 30-40 minutes

#### Option B: DistilBERT (Higher Accuracy)

**Architecture**:
- DistilBERT tokenizer + model (66M params)
- Fine-tuning on phishing dataset
- Classification head

**Use when**: Server-side inference only  
**Accuracy**: 95-97%  
**Training time**: 1.5-2.5 hours (requires GPU)

**Training Commands**:

```bash
# Train LSTM (default)
python email_bert_training.py emails.csv

# Train DistilBERT
python email_bert_training.py emails.csv --full-bert
```

**Dataset Requirements**:
- CSV with columns: `email_text` or `text`, `label`
- Labels: 0 (legitimate), 1 (phishing)
- Minimum 5,000 samples

---

### 3. SMS Bi-LSTM (`sms_bilstm_training.py`)

**Purpose**: Detect SMS phishing (smishing)

**Architecture**:
- Word embedding (5k vocab, 100 dims)
- 2x Bidirectional LSTM layers
- Dense layers with dropout
- Binary classification output

**Input**: SMS text (max 160 chars)  
**Output**: Phishing probability (0-1)

**Expected Performance**:
- Accuracy: 95-98%
- Training time: 20-25 minutes (CPU)

**Dataset Requirements**:
- CSV with columns: `sms_text` or `text`, `label`
- Labels: 0/ham/legitimate or 1/spam/phishing
- Minimum 5,000 samples

**Special Features**:
- Text cleaning (URLs, phone numbers)
- Class weighting for imbalanced data
- Spatial dropout for regularization

---

## üéØ Training Output

Each script produces:

1. **Console logs** with training progress
2. **Evaluation metrics** (accuracy, precision, recall, F1)
3. **Confusion matrix**
4. **Classification report**
5. **TensorFlow.js model** in `/public/models/`
6. **Metadata JSON** with training info

**Example Output**:

```
üöÄ URL PHISHING DETECTION - CHARACTER CNN TRAINING
======================================================================

üìÇ Loading URL dataset...
‚úÖ Loaded 50000 URLs
   - Safe URLs: 25000
   - Phishing URLs: 25000

üîß Preprocessing URLs (max length: 200)...

üìä Splitting dataset (test size: 0.15)...
   - Training samples: 42500
   - Test samples: 7500

üèóÔ∏è Building Character-CNN model...
‚úÖ Model architecture:
Model: "sequential"
_________________________________________________________________
Layer (type)                Output Shape              Param #   
=================================================================
char_embedding (Embedding)  (None, 200, 64)           8192      
conv1d_1 (Conv1D)          (None, 200, 128)          57472     
...

üéØ Training model (epochs: 20, batch size: 64)...
Epoch 1/20
665/665 [==============================] - 45s - loss: 0.3421 - accuracy: 0.8534
...

üìà Evaluating model on test set...

======================================================================
üìä FINAL EVALUATION METRICS
======================================================================
Accuracy:  0.9245 (92.45%)
Precision: 0.9321 (93.21%)
Recall:    0.9178 (91.78%)
F1-Score:  0.9249 (92.49%)
Loss:      0.1876
======================================================================

üíæ Saving models...
   ‚úÖ Saved TensorFlow model to: ./models/url_model
   ‚úÖ Saved TensorFlow.js model to: ./public/models/url
   ‚úÖ Saved metadata to: ./public/models/url/metadata.json

‚ú® Training complete!
```

---

## üîß Troubleshooting

### Issue: `ModuleNotFoundError: No module named 'tensorflow'`

**Solution**:
```bash
pip install tensorflow==2.15.0
```

---

### Issue: `CUDA out of memory`

**Solutions**:
1. Reduce batch size in script (edit `BATCH_SIZE = 32` or `16`)
2. Use CPU instead of GPU:
   ```python
   import os
   os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
   ```

---

### Issue: `KeyError: 'url'` or `KeyError: 'label'`

**Cause**: Dataset columns don't match expected names

**Solution**: Check your CSV column names
```bash
head -1 your_dataset.csv
```

If different, the script will try to auto-detect common variations:
- Text columns: `url`, `text`, `email_text`, `sms_text`, `content`, `message`
- Label columns: `label`, `class`, `target`, `spam`

---

### Issue: Low accuracy (<80%)

**Solutions**:
1. **Increase dataset size**: Aim for 50k+ samples
2. **Increase epochs**: Change `EPOCHS = 30` in script
3. **Check data quality**: Look for mislabeled samples
4. **Balance dataset**: Ensure roughly equal safe/phishing samples
5. **Add data augmentation**: For text models, use synonyms or paraphrasing

---

### Issue: Model too large for browser

**Solutions**:
1. **Use quantization**:
   ```bash
   tensorflowjs_converter \
       --input_format=keras \
       --quantize_uint8 \
       ./models/url_model \
       ./public/models/url
   ```
2. **Reduce vocabulary**: Change `VOCAB_SIZE = 5000` (from 10000)
3. **Reduce embedding dims**: Change `EMBEDDING_DIM = 64` (from 128)

---

## üìö Advanced Usage

### Custom Hyperparameters

Edit constants at the top of each script:

```python
# url_cnn_training.py
MAX_URL_LENGTH = 200       # Increase for longer URLs
VOCAB_SIZE = 128           # ASCII character set
EMBEDDING_DIM = 64         # Embedding dimensions
BATCH_SIZE = 64            # Batch size
EPOCHS = 20                # Training epochs
```

### Model Checkpointing

Models automatically save the best version during training:

```python
keras.callbacks.ModelCheckpoint(
    MODEL_SAVE_PATH + '_best.h5',
    monitor='val_accuracy',
    save_best_only=True
)
```

### Early Stopping

Training stops if validation loss doesn't improve for 5 epochs:

```python
keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)
```

### Learning Rate Scheduling

Learning rate reduces by 50% if validation loss plateaus:

```python
keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=3
)
```

---

## üéì For Academic Evaluation

### Model Architecture Justification

**Q: Why Character-CNN for URLs?**  
A: Character-level models detect typosquatting and domain manipulation better than word-level models. URLs don't follow natural language patterns.

**Q: Why Bi-LSTM for Email/SMS?**  
A: Bidirectional processing captures context from both directions, essential for understanding phishing tactics that rely on specific word order.

**Q: Why not transformers everywhere?**  
A: Transformers (BERT) are excellent for accuracy but too large for browser deployment. We provide both options.

### Expected Questions & Answers

**Q: What datasets did you use?**  
A: Public Kaggle datasets with 10k-50k samples each:
- URL: [Phishing URLs Dataset](https://www.kaggle.com/datasets/taruntiwarihp/phishing-site-urls)
- Email: [Phishing Emails](https://www.kaggle.com/datasets/subhajournal/phishingemails)
- SMS: [SMS Spam Collection](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)

**Q: How did you handle imbalanced data?**  
A: Used class weighting in loss function to give more importance to minority class (phishing samples).

**Q: What are your evaluation metrics?**  
A: Standard ML metrics:
- Accuracy (overall correctness)
- Precision (false positive rate)
- Recall (false negative rate)
- F1-Score (harmonic mean)

**Q: How long did training take?**  
A: 
- URL CNN: 15-20 min (CPU)
- Email LSTM: 30-40 min (CPU)
- Email BERT: 1.5-2.5 hours (GPU recommended)
- SMS Bi-LSTM: 20-25 min (CPU)

**Q: Can you demonstrate the models working?**  
A: Yes - models are deployed in the web app at [phishguard-web-phishing-detector-eky2mdxr.sites.blink.new](https://phishguard-web-phishing-detector-eky2mdxr.sites.blink.new)

---

## üìß Support

For questions about training:
1. Check script comments - they explain each step
2. Review console output - shows progress and errors
3. Verify dataset format - ensure correct columns
4. Check GPU memory - reduce batch size if needed

**Training completed successfully? Copy models to `/public/models/` and update backend!**

---

## üéâ Next Steps

1. ‚úÖ Train all three models
2. ‚úÖ Verify output in `/public/models/`
3. ‚úÖ Copy to PhishGuard app
4. ‚úÖ Update backend edge function (uncomment model loading)
5. ‚úÖ Test with sample inputs
6. ‚úÖ Deploy to production

**Congratulations! You're ready for academic defense with real ML models.**
